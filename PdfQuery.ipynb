{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQoaiOKpH7_O"
      },
      "source": [
        "Get Answers from PDF Using Langchain and Astradb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -q cassio datasets langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twz6f7tcvlGt"
      },
      "outputs": [],
      "source": [
        "# Lanchain components to use\n",
        "from langchain.vectorstores.cassandra import Cassandra # libaries in langchain help to connect with cassandra db and perform necessary tasks like text embeddings\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper # wrap vector in one specific  package\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings # convert text to vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F48F3CzsyhkY"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset # to use dataset from huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh5LN27ly32R"
      },
      "outputs": [],
      "source": [
        "import cassio # for Astra DB integration in Langchain. Also, to initialize the DB coonection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install PyPDF2 # library to read text present inside the pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r982Ntkzbih"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader # to read text from pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqU64F8N0o00"
      },
      "outputs": [],
      "source": [
        "# to connect to Astra DB hosted in Cloud\n",
        "ASTRA_DB_APPLICATION_TOKEN = 'Enter your token here'\n",
        "ASTRA_DB_ID = 'Enter your ID here'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xkt3OkLp0L8p"
      },
      "outputs": [],
      "source": [
        "# to use Openaiapi features\n",
        "OPENAI_API_KEY = \"Enter your key here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJEu9rES2FDf"
      },
      "outputs": [],
      "source": [
        "# providing pdf path\n",
        "pdfreader = PdfReader('/content/budget_speech.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0ZzdQNQ2ipX"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "raw_text = \" \"\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "  content = page.extract_text()\n",
        "  if content:\n",
        "    raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Zzj4QPJ3llh"
      },
      "outputs": [],
      "source": [
        "#Initialize connection to my database\n",
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cImIRem24TP6"
      },
      "outputs": [],
      "source": [
        "# Created Langchain embedding and LLM objects\n",
        "llm = OpenAI(openai_api_key = OPENAI_API_KEY)\n",
        "embedding = OpenAIEmbeddings(open_ai_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating Langchain vector store\n",
        "astra_vector_store = Cassandra(\n",
        "   embedding = embedding,\n",
        "   table_name = \"qa_mini_demo\",\n",
        "   session = \"None\",\n",
        "   keyspace = \"None\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I8T-Xh35yfY"
      },
      "outputs": [],
      "source": [
        "from langchain.textsplitter import CharacterTextSplitter\n",
        "\n",
        "# Splitting the text using Character Text Split such that it does not increase token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6zA3PF15n5t"
      },
      "outputs": [],
      "source": [
        "texts[:50] # to see top 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncXjvH3T60mc"
      },
      "outputs": [],
      "source": [
        "# Loading top 50 into the vector store and converting text to embeddings\n",
        "astra_vector_store.add_texts(texts[:50])\n",
        "print(\"Inserted %i headlines.\" % len(texts[:50]))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore = astra_vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljXPy1B38kIM"
      },
      "outputs": [],
      "source": [
        "# Running QA\n",
        "first_question = True\n",
        "while True:\n",
        "  if first_question:\n",
        "    query_text = input(\"\\nEnter your question (or type 'quit' to exit):\").strip()\n",
        "  else:\n",
        "      query_text = input(\"\\nWhat's your next question (or type 'quit' to exit):\").strip()\n",
        "\n",
        "  if query_text.lower()== 'quit':\n",
        "      break\n",
        "\n",
        "  if query_text == '':\n",
        "      continue\n",
        "\n",
        "  first_question = False\n",
        "\n",
        "  print('\\nQUESTION: \\'%s\\\"\" % query_text')\n",
        "  answer = astra_vector_index.query(query_text, llm = llm).strip()\n",
        "  print(\"ANSWER: \\'%s\\'n\" % answer)\n",
        "\n",
        "  print(\"FIRST DOCUMENTS BY RELAVANCE:\")\n",
        "  for doc, score in astra_vector_store.similarity_search_with_score(query_text, k = 4):\n",
        "    print(\"     [%0.4f]  \\\"%s ...\\\"\" % (score, doc.page_content[:84]))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
